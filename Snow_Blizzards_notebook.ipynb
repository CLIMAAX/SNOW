{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114c11c0-af34-4523-92fb-9a0d62cd518b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hazard assessment for heavy snowfall & blizzards\n",
    "\n",
    "Click [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CLIMAAX/DROUGHTS/main?labpath=DROUGHTS_notebook_2.ipynb) to launch this workflow on MyBinder. \n",
    "\n",
    "This is the first and simplest snow workflow.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096c862-1b27-4fcf-bfd2-d85c5d3e3b22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hazard assessment methodology\n",
    "\n",
    "The method involves visually representing the susceptible population exposed to intense snowfall and blizzards. This can be achieved by overlaying indicators for heavy snowfall and blizzards with population data. The objective is to comprehend the current likelihood of severe snowfall and blizzards and identify the specific regions in Europe that are most affected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5268cbd-a0f4-4d66-a20c-b44723d92443",
   "metadata": {},
   "source": [
    "### Blizzard  \n",
    "\n",
    "A blizzard is a severe storm condition defined by low temperature, sustained wind or frequent wind gust and considerable precipitating or blowing snow. For blizzard conditions we propose the use of following impact indicator:\n",
    "\n",
    "**Blizzard days** = Tmean  ≤ 0 °C, Rs (snow amount) ≥ 10 cm and Wg (wind gust) ≥ 17 m/s ( Vajda et al., 2014). \n",
    "\n",
    "This impact indicator was defined taking into account the exposure of critical infrastructure, i.e., roads, rails, power lines, telecommunication to the hazard and is based on an extensive literature review, media reports, surveys conducted with European CI operators and case studies. \n",
    "\n",
    "\n",
    "### Heavy Snow \n",
    "\n",
    "Heavy snowfall may cause many disruptions and impacts in various sectors; however, the impacts and consequences of this hazard depend on the affected sector, infrastructure and also preparedness of society that varies over Europe.  For example, already a few centimeters of snow can disrupt road traffic, but doesn’t normally cause any harm to energy infrastructure. Many weather services have three warning levels based on the severity of expected impacts, which are typically different for different sectors of infrastructure. There is a large variation in the national warning criteria or thresholds.\n",
    "\n",
    "Similarly to blizzard, the impact indicators for heavy snowfall were defined taking into account the exposure of critical infrastructure, i.e., roads, rails, power lines, telecommunication to the hazard and is based on an extensive literature review, media reports, surveys conducted with European CI operators and case studies. The qualitative description of the two-level thresholds are:\n",
    "\n",
    "**1st threshold ( > 6 cm):** Some adverse impacts are expected, their severity depends on the resilience of the system, transportation is mainly affected.\n",
    "\n",
    "**2nd threshold ( > 25 cm):**  The weather phenomena are so severe that is likely that adverse impact will occur, CI system is seriously impacted.\n",
    "\n",
    "This code calculates the Annual probability (%) of a blizzard and heavy snowfall days during the specified period and a region of interest.\n",
    "\n",
    "\n",
    "**The annual probability is calualted using following equation**\n",
    "\n",
    "P =    ((variable > threshold) / days in year ) X 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825852ee-1dbe-4640-a2f2-964fa2795ec1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparation work\n",
    "\n",
    "### Select area of interest\n",
    "Before downloading the data, we will define the coordinates of the area of interest. Based on these coordinates we will be able to clip the datasets for further processing, and eventually display hazard and damage maps for the selected area.\n",
    "\n",
    " area = [Lat_north, Lon_east, Lat_south, Lon_west,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56eeba12-9595-4043-b8d0-2675b77f7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lat Lon for area interest\n",
    "area = [80, -10, 20, 45,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3282b-3e2a-45e0-bc56-669f5c699d42",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load libraries\n",
    "\n",
    "In this notebook we will use the following Python libraries:\n",
    "- [warnings](https://docs.python.org/3/library/warnings.html) - To control the Python warning message \n",
    "- [cdsapi](https://pypi.org/project/cdsapi/) - To access the  CDS data\n",
    "- [os](https://docs.python.org/3/library/os.html) - To create directories and work with files\n",
    "- [pathlib](https://docs.python.org/3/library/pathlib.html) - To create Object-oriented filesystem paths\n",
    "- [pooch](https://www.fatiando.org/pooch/latest/index.html) - To download and unzip the data\n",
    "- [urllib](https://docs.python.org/3/library/urllib.html) - package for working with URLs\n",
    "- [xarray](https://docs.xarray.dev/en/stable/) - To process the NetCDF data and prepare it for further calculation\n",
    "- [xclim](https://xclim.readthedocs.io/en/stable/installation.html) - To correct the required data units\n",
    "- [xesmf](https://xesmf.readthedocs.io/en/stable/) - Universal regridder for geospatial data\n",
    "- [rioxarray](https://corteva.github.io/rioxarray/stable/) - Rasterio xarray extension - to make it easier to use GeoTIFF data with xarray\n",
    "- [rasterio](https://rasterio.readthedocs.io/en/stable/) - To access and explore geospatial raster data in GeoTIFF format\n",
    "- [np](https://numpy.org) - Numerical computing tools  \n",
    "- [matplotlib](https://matplotlib.org/) - To plot the maps \n",
    "- [cartopy](https://scitools.org.uk/cartopy/docs/latest/) - To plot the maps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edbe9e6f-83c3-4567-9e9e-1b21408a0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*The 'nopython' keyword.*\")\n",
    "\n",
    "import cdsapi\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pooch\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import xarray as xr\n",
    "import xclim as xc\n",
    "import xesmf as xe\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba64234-5011-4c3a-8d56-c08ed743efb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Create the directory structure \n",
    "\n",
    "In order for this workflow to work even if you download and use just this notebook, we need to set up the directory structure.\n",
    "Next cell will create the directory called 'snow_workflow' in the same directory where this notebook is saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "262714f0-48e3-451c-a1c3-186a056f3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_folder = 'snow_workflow'\n",
    "if not os.path.exists(workflow_folder):\n",
    "    os.makedirs(workflow_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1433fbba-fa30-497c-a20f-9c785d41fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(workflow_folder,'data')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c904970-2f29-4120-a49a-2456e7681c2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Access and view dataset\n",
    "\n",
    "In this workflow, we will have a mix of data available to download through API and the data that must be manually downloaded from the website.\n",
    "\n",
    "Since there is no API to download population data, we can use **[pooch](https://www.fatiando.org/pooch/latest/index.html)** library to download and unzip it. \n",
    "\n",
    "Pooch will check if the zip file already exists by comparing the hash of the file with what is stored in the default and only download it if it is not already there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8dd75c-c048-4fea-9e93-a8b7f17e485e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Download ERA5 and load data into memory\n",
    "\n",
    "We downloaded [ERA5 single level dataset](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview)  using the CDS API from the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/#!/home). We require several variables to calculate these indicator, which are at an hourly frequency. Consequently, this analysis is limited to the data period from 1991 to 2010.\n",
    "\n",
    "We are currently retrieving data for demonstration purposes only at 00:00, 06:00, 12:00, and 18:00 UTC. However, it is feasible to obtain data for all 24 time steps. It is important to mention that we are focusing on only 4-time steps with a 6-hour interval. However, the variable \"wind gust\" displays the value from one hour before rather than 6 hours. Nevertheless, it remains a reliable representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301733b-3217-4abe-82af-1a498856bf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 05:05:11,894 INFO Welcome to the CDS\n",
      "2024-02-16 05:05:11,896 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2024-02-16 05:05:12,050 INFO Request is queued\n"
     ]
    }
   ],
   "source": [
    "c = cdsapi.Client()\n",
    "\n",
    "day_range=np.arange(1,32)\n",
    "month_range=np.array((1,2,3,10,11,12))\n",
    "varnames=['2m_temperature','10m_wind_gust_since_previous_post_processing','snow_depth','snow_density']\n",
    "dataset = 'reanalysis-era5-single-levels'\n",
    "\n",
    "# API request\n",
    "params = {'format': 'netcdf',\n",
    "        'product_type': 'reanalysis',\n",
    "        'variable': varnames,\n",
    "        'year': list(map(str, range(2005, 2010))),\n",
    "        'month': list(map(\"{:02d}\".format, range(1,13))),\n",
    "        'time': ['00:00', '06:00', '12:00', '18:00', ],\n",
    "        'day': list(np.char.zfill(list(map(str, day_range)),2)),\n",
    "        'grid': [0.25, 0.25],\n",
    "        'area':area,}\n",
    "\n",
    "# retrieve the location of the file\n",
    "fl = c.retrieve(dataset, params)\n",
    "\n",
    "# load into memory\n",
    "with urlopen(fl.location) as f:\n",
    "    ds = xr.open_dataset(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca18c22-080e-4847-9fee-95ceaebcfe0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Population data\n",
    "\n",
    "In this illustration, we are using population data sourced from the JRC data portal, specifically the Global Human Settlement Layer [Global Human Settlement Layer GHSL](https://ghsl.jrc.ec.europa.eu/download.php?ds=pop), with 30 arcsec resolution global datasets. After downloading and extracting the data, Pooch will list the contents within the data directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e827f09-9028-4394-b334-30c432f44e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/GHS_POP_GLOBE_R2023A/GHS_POP_E2015_GLOBE_R2023A_4326_30ss/V1-0/GHS_POP_E2015_GLOBE_R2023A_4326_30ss_V1_0.zip'\n",
    "pooch.retrieve(\n",
    "    url=url,\n",
    "    known_hash=None,\n",
    "    path=data_dir,\n",
    "    processor=pooch.Unzip(extract_dir=''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a790e5d5-e377-4573-824d-0277fdedb22d",
   "metadata": {},
   "source": [
    "The zip file contains data, as well as metadata and the documentation in the pdf file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8b004-ca47-41fc-b918-cb2efaf90223",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d0041-36d7-4bd5-ba02-552c8d5cdb5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Population data\n",
    "\n",
    "Population data is in file with filename: **GHS_POP_E2015_GLOBE_R2023A_4326_30ss_V1_0.tif**\n",
    "\n",
    "We can use rioxarray to load this file and explore the projections of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62471b9-d92d-43d6-949e-c1a40410e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_population = f'{data_dir}/GHS_POP_E2015_GLOBE_R2023A_4326_30ss_V1_0.tif'\n",
    "\n",
    "population = rxr.open_rasterio(filename_population)\n",
    "population\n",
    "\n",
    "population = population.rename({'x': 'longitude','y': 'latitude'})\n",
    "population.rio.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab4654-154e-41dd-8704-29619dc1079e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note that now, we have a directory **snow_workflow/data** where all the zip files and unzipped files are stored.\n",
    "\n",
    "We can list all the files in the **data_dir** using the **os** library.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e307a949-cdb3-4099-b442-cf21621163b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with os.scandir(data_dir) as entries:\n",
    "    for entry in entries:\n",
    "        print(entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9d2622-6446-42c1-8b6e-a56f2f4c9e13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process the data\n",
    "\n",
    "### ERA5 data\n",
    "#### Convert unit of input variables \n",
    "Temperature (Kelvin) --> Temperature -273.15 (deg C)\n",
    "\n",
    "Snow depth  (m of water equivalent)  -->Snow depth (cm) \n",
    "\n",
    "   Snow depth (m) = (RW X SD) / RSN\n",
    "   \n",
    "     where:\n",
    "      SD= snow depth in m of water equivalent\n",
    "      RW, density of water, = 1000 kg/m3\n",
    "      RSN = density of snow in kg/m3\n",
    " Snow depth (cm) --> Snow depth (m) X 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac1b15-5cc8-46f7-be9b-ae6bc1c5110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['t2m']  = xc.units.convert_units_to(ds.t2m, \"degC\")\n",
    "\n",
    "ds['snow_depth'] = 1000 * ds.sd / ds.rsn\n",
    "ds = ds.drop(['sd','rsn'])\n",
    "ds['snow_depth'] = ds.snow_depth.assign_attrs(units=\"m\", description=\"snow depth\")\n",
    "ds['snow_depth'] = xc.units.convert_units_to(ds.snow_depth, \"cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f049cf8-5e47-4ff3-a2b7-c2aeb3ccc18c",
   "metadata": {
    "tags": []
   },
   "source": [
    "####  Resampling to daily data\n",
    "\n",
    "According to the ERA5 convention, accumulated variables aggregate data from 00 UTC to the next 24 hours (i.e., the accumulation at 00 UTC represents the sum of values during the previous day). Therefore, before archiving accumulated variables, we shifted the time axis by one timestep to ensure that the accumulations at 00 UTC correspond to the actual day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20be10b-da77-43a3-849a-23e5b1e8fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.shift(time=1)\n",
    "\n",
    "tas_day        = ds.t2m.resample(time='24H').mean('time')\n",
    "wspd_day       = ds.fg10.resample(time='24H').max('time')\n",
    "snow_depth_day = ds.snow_depth.resample(time='24H').mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41192db8-ad74-4969-ae02-c6b47f61dcda",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The Heavy snowfall & blizzards Indicator\n",
    "\n",
    "\n",
    "### Define thresholds \n",
    "\n",
    "**Thresholds for Blizzard days**\n",
    "\n",
    "Temperature threshold --> lim_tas    = 0.\n",
    "\n",
    "Snow threshold          -->lim_snow10 = 10.\n",
    "\n",
    "Wind gust threshold   -->lim_gust   = 17.\n",
    "\n",
    "\n",
    "**Heavy Snow thresholds** \n",
    "\n",
    "Snow exceding 6cm threshold  -->lim_snow6  = 6.\n",
    "\n",
    "Snow exceding 25cm threshold -->lim_snow25 = 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d50ed1-7aca-40f3-90c7-3f2443410a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| Define thresholds \n",
    "lim_tas    = 0.\n",
    "lim_snow10 = 10.\n",
    "lim_gust   = 17.\n",
    "\n",
    "lim_snow6  = 6.\n",
    "lim_snow25 = 25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f09be8-ac7f-4b07-b855-0a95f16810eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Calculate the probability of occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60376e4d-cd99-44b7-a06d-0b34af8a7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| The probability of occurrence of at least one blizzard day\n",
    "\n",
    "BdayCount_anaProb = ((tas_day\n",
    "                      < lim_tas) * (snow_depth_day > lim_snow10) * (wspd_day > lim_gust)).groupby('time.year').sum('time')\n",
    "#del tas_day, wspd_day\n",
    "total_days_per_year = snow_depth_day.groupby('time.year').count(dim='time')\n",
    "\n",
    "BdayCount_anaProb = (BdayCount_anaProb / total_days_per_year) * 100\n",
    "\n",
    "BdayCount_anaProb = BdayCount_anaProb.where(BdayCount_anaProb != 0.)\n",
    "BdayCount_anaProb = BdayCount_anaProb.assign_attrs(units=\"%\", long_name=\"Annual probability of blizzard days\")\n",
    "BdayCount_anaProb = BdayCount_anaProb.to_dataset(name='blizzard_days')\n",
    "\n",
    "BdayCount_anaProb_mean = BdayCount_anaProb.mean('year')\n",
    "\n",
    "BdayCount_anaProb_mean.to_netcdf(path=os.path.join(data_dir, \"BdayCount_AnaProb_mean.nc\"))\n",
    "del BdayCount_anaProb\n",
    "\n",
    "\n",
    "#| Probability of occurrence of at least one day with snowfall > 6cm\n",
    "\n",
    "snow6Count_anaProb = (snow_depth_day > lim_snow6).groupby('time.year').sum('time')\n",
    "\n",
    "snow6Prob_annual = (snow6Count_anaProb / total_days_per_year) * 100\n",
    "\n",
    "snow6Prob_annual = snow6Prob_annual.where(snow6Prob_annual != 0.)\n",
    "snow6Prob_annual = snow6Prob_annual.assign_attrs(units=\"%\", long_name=\"Annual probability of snow days\")\n",
    "snow6Prob_annual = snow6Prob_annual.to_dataset(name='snow_days')\n",
    "\n",
    "snow6Prob_annual_mean = snow6Prob_annual.mean('year')\n",
    "snow6Prob_annual_mean.to_netcdf(path=os.path.join(data_dir, \"snow6Prob_annual_mean.nc\"))\n",
    "del snow6Prob_annual\n",
    "\n",
    "\n",
    "#| Probability of occurrence of at least one day with snowfall > 25cm\n",
    "snow25Count_anaProb = (snow_depth_day > lim_snow25).groupby('time.year').sum('time')\n",
    "\n",
    "snow25Prob_annual = (snow25Count_anaProb / total_days_per_year) * 100\n",
    "\n",
    "snow25Prob_annual = snow25Prob_annual.where(snow25Prob_annual != 0.)\n",
    "snow25Prob_annual = snow25Prob_annual.assign_attrs(units=\"%\", long_name=\"Annual probability of snow days\")\n",
    "snow25Prob_annual = snow25Prob_annual.to_dataset(name='snow_days')\n",
    "\n",
    "snow25Prob_annual_mean = snow25Prob_annual.mean('year')\n",
    "snow25Prob_annual_mean.to_netcdf(path=os.path.join(data_dir, \"snow25Prob_annual_mean.nc\"))\n",
    "del snow25Prob_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ffe153-dd1c-4251-a44d-b6d75221fade",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "###  population data\n",
    "\n",
    "In this workflow, we want to overlay the population data on snowfall and blizzard indicators to better understand where these indicators affect densely populated areas. \n",
    "\n",
    "Take a closer look at the dimensions and coordinates of our two data objects. \n",
    "- Notice that the population data has **x** and **y** as spatial dimensions, while ERA5 has **latitude** and **longitude**. \n",
    "- Both datasets are in the same projection: **WSG84/epsg 4326**. \n",
    "- However, the resolutions of the datasets are different. \n",
    "\n",
    "To be able to plot these two datasets together, we must have them at the same resolution and zoomed in to the same area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d18fa7-ceb4-4399-8952-770e0cbeffb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "**regrid the population data** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d338889-cd91-4f3b-9d16-b78a4f2a91e1",
   "metadata": {},
   "source": [
    "We utilize the xESMF library, a Universal Regridder for Geospatial Data, to regrid the population data to match the ERA5 resolution. Prior to regridding, the population data is cropped specifically for the European region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663cba37-97c2-4baf-9e22-5aa720730231",
   "metadata": {},
   "outputs": [],
   "source": [
    "Europe_population = population.sel(latitude=slice(80.0,20.0), longitude=slice(-10.0,45.0))\n",
    "\n",
    "snow6Prob_annual_mean.rio.crs\n",
    "snow6Prob_annual_mean.rio.write_crs(4326, inplace=True)\n",
    "\n",
    "regridder = xe.Regridder(Europe_population, snow6Prob_annual_mean, 'bilinear', periodic=True)\n",
    " \n",
    "Europe_population_025deg = regridder(Europe_population)\n",
    "\n",
    "Europe_population_025deg.to_netcdf(path=os.path.join(data_dir, \"Europe_population_25deg.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dabc5a6-8397-414e-b560-d21f988b21c5",
   "metadata": {},
   "source": [
    "**Explore the regridded population data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b701727-1b22-43ef-b99f-00eb3e50e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Europe_population_025deg['band']\n",
    "del Europe_population_025deg['spatial_ref']\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "p_levels = [ 1,10,50,100,500,1000]\n",
    "\n",
    "p = Europe_population_025deg.plot(\n",
    "    subplot_kws=dict(projection=ccrs.Orthographic(0, 35)),\n",
    "    levels=p_levels,\n",
    "    cbar_kwargs={\"label\": \"population density\"},\n",
    "    cmap=\"hot_r\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "p.axes.coastlines()\n",
    "plt.title(' ', loc = \"left\")\n",
    "plt.title('population density ', loc = \"left\")\n",
    "\n",
    "# Add coastlines and features\n",
    "\n",
    "p.axes.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "p.axes.add_feature(cfeature.LAND, edgecolor='black', facecolor='none')\n",
    "\n",
    "# Add latitude and longitude labels\n",
    "gl = p.axes.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                      linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "#gl.xformatter = LONGITUDE_FORMATTER\n",
    "#gl.yformatter = LATITUDE_FORMATTER\n",
    "plt.savefig('/Users/poladesu/D_Drive/Prog_FMI/dmin_CLIMAAX/snow_workflow/data/population_density_map.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c954997-6b8f-488c-be83-babd74f36c8e",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Visualize the hazard data\n",
    "Having acquired the data and computed the required indicator, we proceed to create visual plots for data exploration. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4e50d-13b2-4e66-a14c-ab527a7dadd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Annual probability plot of indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354af1b9-4cc3-41e7-865f-59bc6372a836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.warnings.filterwarnings('ignore')\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "p_levels = [ 1,2,4, 6,8]\n",
    "\n",
    "p = BdayCount_anaProb_mean.blizzard_days.plot(\n",
    "    subplot_kws=dict(projection=ccrs.Orthographic(0, 35)),\n",
    "    levels=p_levels, \n",
    "    cbar_kwargs={\"label\": \"  \"},\n",
    "    cmap=\"GnBu\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "p.axes.coastlines()\n",
    "plt.title('Annual probability (%) of blizzard days', loc = \"left\")\n",
    "\n",
    "# Add coastlines and features\n",
    "\n",
    "p.axes.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "p.axes.add_feature(cfeature.LAND, edgecolor='black', facecolor='none')\n",
    "p.axes.add_feature(cfeature.OCEAN, edgecolor='black', facecolor='aliceblue')\n",
    "\n",
    "# Add latitude and longitude labels\n",
    "gl = p.axes.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                      linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94401ec-168c-437d-9647-116aaa605214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the data to exclude values less than 1\n",
    "filtered_data = snow6Prob_annual_mean.snow_days.where(snow6Prob_annual_mean.snow_days >= 1)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "p_levels = [1, 10, 20, 30, 40, 50]\n",
    "\n",
    "p = filtered_data.plot(\n",
    "    subplot_kws=dict(projection=ccrs.Orthographic(0, 35)),\n",
    "    levels=p_levels,\n",
    "    cmap=\"GnBu\",\n",
    "    cbar_kwargs={\"label\": \" \"},\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "p.axes.coastlines()\n",
    "plt.title('Annual probability (%) of snowfall days > 6 cm  ', loc=\"left\")\n",
    "\n",
    "# Add coastlines and features\n",
    "p.axes.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "p.axes.add_feature(cfeature.LAND, edgecolor='black', facecolor='none')\n",
    "p.axes.add_feature(cfeature.OCEAN, edgecolor='black', facecolor='aliceblue')\n",
    "\n",
    "# Add latitude and longitude labels\n",
    "gl = p.axes.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                      linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750bc9ae-36d1-4321-8a3b-a33be8c06509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the data to exclude values less than 1\n",
    "filtered_data = snow25Prob_annual_mean.snow_days.where(snow25Prob_annual_mean.snow_days >= 1)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "p_levels = [1, 10, 20, 30, 40]\n",
    "\n",
    "p = filtered_data.plot(\n",
    "    subplot_kws=dict(projection=ccrs.Orthographic(0, 35)),\n",
    "    levels=p_levels,\n",
    "    cmap=\"GnBu\",\n",
    "    cbar_kwargs={\"label\": \" \"},\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "p.axes.coastlines()\n",
    "plt.title('Annual probability (%) of snowfall days > 25 cm  ', loc=\"left\")\n",
    "\n",
    "# Add coastlines and features\n",
    "p.axes.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "p.axes.add_feature(cfeature.LAND, edgecolor='black', facecolor='none')\n",
    "p.axes.add_feature(cfeature.OCEAN, edgecolor='black', facecolor='aliceblue')\n",
    "\n",
    "# Add latitude and longitude labels\n",
    "gl = p.axes.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                      linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc02ec79-82b5-493f-b5a7-f588eda2f71f",
   "metadata": {},
   "source": [
    "**Explore the regridded population data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4ae16-1925-40aa-9b54-a3dd5b6d8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Europe_population_025deg['band']\n",
    "del Europe_population_025deg['spatial_ref']\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "p_levels = [ 1,10,50,100,500,1000]\n",
    "\n",
    "p = Europe_population_025deg.plot(\n",
    "    subplot_kws=dict(projection=ccrs.Orthographic(0, 35)),\n",
    "    levels=p_levels,\n",
    "    cbar_kwargs={\"label\": \"population density\"},\n",
    "    cmap=\"hot_r\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "p.axes.coastlines()\n",
    "plt.title(' ', loc = \"left\")\n",
    "plt.title('population density ', loc = \"left\")\n",
    "\n",
    "# Add coastlines and features\n",
    "\n",
    "p.axes.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "p.axes.add_feature(cfeature.LAND, edgecolor='black', facecolor='none')\n",
    "\n",
    "# Add latitude and longitude labels\n",
    "gl = p.axes.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                      linewidth=1, color='gray', alpha=0.5, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "#gl.xformatter = LONGITUDE_FORMATTER\n",
    "#gl.yformatter = LATITUDE_FORMATTER\n",
    "plt.savefig('/Users/poladesu/D_Drive/Prog_FMI/dmin_CLIMAAX/snow_workflow/data/population_density_map.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f5b28-32cf-4e47-80cd-cc3db96ffa00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select the area of interest\n",
    "We are currently selecting the Alpine region because pollution density is higher in this area, and there is also a greater probability of heavy snow and blizzards, using the specified latitude and longitude extents, which can be modified as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0922d35-4b7f-4b1b-a513-2fcddb10a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin=4  # Min Longitude \n",
    "xmax=15 # Max Longitude \n",
    "\n",
    "ymin=42 # Min Latitude \n",
    "ymax=50 # Max Latitude \n",
    "\n",
    "SelArea_population = Europe_population_025deg.sel(latitude=slice(ymax,ymin), longitude=slice(xmin,xmax))\n",
    "\n",
    "SelArea_6cm_ind = snow6Prob_annual_mean.sel(latitude=slice(ymax,ymin), longitude=slice(xmin,xmax))\n",
    "SelArea_25cm_ind = snow25Prob_annual_mean.sel(latitude=slice(ymax,ymin), longitude=slice(xmin,xmax))\n",
    "SelArea_blizard_ind = BdayCount_anaProb_mean.sel(latitude=slice(ymax,ymin), longitude=slice(xmin,xmax))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccd235-5711-44d3-877b-486519f77502",
   "metadata": {
    "tags": []
   },
   "source": [
    "### To explore the exposure and vulnerability of the population, plot them together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42096edd-6abe-4854-97da-aad92906b4ca",
   "metadata": {},
   "source": [
    "We are considering two approaches: 1) overlaying population density on snow indices and 2) exclusively plotting snow indices in regions where population density surpasses 1/km.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2285db-138b-4257-9d8f-7957779076ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for snow data where pollution density is below 1\n",
    "snow_data_masked = SelArea_6cm_ind.snow_days.where(SelArea_population >= 1)\n",
    "\n",
    "# Plot snow probability\n",
    "fig, ax1 = plt.subplots(subplot_kw={'projection': ccrs.Orthographic(0, 35)})\n",
    "\n",
    "snow_levels = [0, 1, 5, 10, 30, 40]\n",
    "pop_levels = [1, 10, 30, 60, 100, 500, 1000]\n",
    "\n",
    "snow_data_masked.plot(\n",
    "    ax=ax1,\n",
    "    levels=snow_levels,\n",
    "    cmap=\"GnBu\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cbar_kwargs={\"label\": \"Snow days\", \"shrink\": 0.8},\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "ax1.coastlines()\n",
    "ax1.set_title('Annual probability (%) of snowfall exceeding 6 cm', loc=\"left\")\n",
    "\n",
    "# Add coastlines and features\n",
    "ax1.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax1.add_feature(cfeature.LAND, edgecolor='black', facecolor='none')\n",
    "\n",
    "# Add latitude and longitude labels\n",
    "gl = ax1.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                   linewidth=1, color='gray', alpha=1, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "# Overlay population density on the same subplot\n",
    "mesh = SelArea_population.plot(\n",
    "    ax=ax1,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cmap=\"hot_r\",\n",
    "    levels=pop_levels,\n",
    "    cbar_kwargs={\"label\": \"Population Density\", \"shrink\": 0.8},\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484059b-6e18-4e5f-b01b-5df45a4039ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for snow data where pollution density is below 1\n",
    "snow_data_masked = SelArea_25cm_ind.snow_days.where(SelArea_population >= 1)\n",
    "\n",
    "# Plot snow probability\n",
    "fig, ax1 = plt.subplots(subplot_kw={'projection': ccrs.Orthographic(0, 35)})\n",
    "\n",
    "snow_levels = [0, 1, 5, 10, 30, 40]\n",
    "pop_levels = [1, 10, 30, 60, 100, 500, 1000]\n",
    "\n",
    "snow_data_masked.plot(\n",
    "    ax=ax1,\n",
    "    levels=snow_levels,\n",
    "    cmap=\"GnBu\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cbar_kwargs={\"label\": \"Snow days\", \"shrink\": 0.8},\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "ax1.coastlines()\n",
    "ax1.set_title('Annual probability (%) of snowfall exceeding 25 cm', loc=\"left\")\n",
    "\n",
    "# Add coastlines and features\n",
    "ax1.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax1.add_feature(cfeature.LAND, edgecolor='black', facecolor='none')\n",
    "\n",
    "# Add latitude and longitude labels\n",
    "gl = ax1.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                   linewidth=1, color='gray', alpha=1, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "# Overlay population density on the same subplot\n",
    "mesh = SelArea_population.plot(\n",
    "    ax=ax1,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cmap=\"hot_r\",\n",
    "    levels=pop_levels,\n",
    "    cbar_kwargs={\"label\": \"Population Density\", \"shrink\": 0.8},\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e70f34-d2b6-4b1d-a725-57fc79793a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for snow data where pollution density is below 1\n",
    "snow_data_masked = SelArea_blizard_ind.blizzard_days.where(SelArea_population > 0)\n",
    "\n",
    "population_masked = SelArea_population.where(SelArea_blizard_ind.blizzard_days > 0)\n",
    "\n",
    "# Plot snow probability\n",
    "fig, ax1 = plt.subplots(subplot_kw={'projection': ccrs.Orthographic(0, 35)})\n",
    "\n",
    "snow_levels = [ 1,5,10,15,20]\n",
    "pop_levels = [1, 10, 30, 60, 100, 500, 1000]\n",
    "\n",
    "snow_data_masked.plot(\n",
    "    ax=ax1,\n",
    "    levels=snow_levels,\n",
    "    cmap=\"GnBu\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cbar_kwargs={\"label\": \"blizzard days\", \"shrink\": 0.8},\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "ax1.coastlines()\n",
    "ax1.set_title('Annual probability (%) of blizzard', loc=\"left\")\n",
    "\n",
    "# Add coastlines and features\n",
    "ax1.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax1.add_feature(cfeature.LAND, edgecolor='black', facecolor='none')\n",
    "\n",
    "# Add latitude and longitude labels\n",
    "gl = ax1.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                   linewidth=1, color='gray', alpha=1, linestyle='--')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "# Overlay population density on the same subplot\n",
    "mesh = population_masked.plot(\n",
    "    ax=ax1,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    cmap=\"hot_r\",\n",
    "    levels=pop_levels,\n",
    "    cbar_kwargs={\"label\": \"Population Density\", \"shrink\": 0.8},\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894fe05-7206-4468-9441-6d974a1a2e27",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusions\n",
    "In this workflow, we've illustrated the process of exploring, processing, and visualizing data necessary for analyzing the influence of heavy snowfall and blizzard day indices on population density. These indices are presented as annual probabilities of occurrence, reflecting the likelihood of a particular event happening over several years. In the present climate, communities in the northern Alpine region face heightened vulnerability to heavy snowfall and blizzards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a12200-0053-4e52-945e-844b6ad72543",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "Suraj Polade, FMI \n",
    "\n",
    "Andrea Vajda, FMI "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
